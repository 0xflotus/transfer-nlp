{"data_csv": "/Users/petermartigny/work/experiments/nlp/data/nmt/simplest_eng_fra.csv",
"vectorizer_file": "vectorizerNMT.json",
"model_state_file": "modelNMT.pth",
"save_dir": "/Users/petermartigny/work/experiments/nlp/models/nmt/nmt_luong_no_sampling",
"logs": "/Users/petermartigny/work/experiments/nlp/models/nmt/nmt_luong_no_sampling/logs/log1",
"glove_filepath": "/Users/petermartigny/work/experiments/nlp/data/glove/glove.6B.100d.txt",
"use_glove": false,
"embedding_size": 10,
"char_embedding_size": 50,
"rnn_hidden_size": 10,
"hidden_dim": 10,
"num_channels": 10,
"seed": 1337,
"learning_rate": 0.001,
"dropout_p": 0.1,
"batch_size": 32,
"num_epochs": 2,
"early_stopping_criteria":5,
"cuda": true,
"catch_keyboard_interrupt": true,
"reload_from_files": false,
"expand_filepaths_to_save_dir": true,
"dataset_cls": "NMTDataset",
"model": "NMTModel",
"gradient_clipping": 0.25,
"conditioned": true,
"source_embedding_size": 64,
"target_embedding_size": 64,
"encoding_size": 64}
