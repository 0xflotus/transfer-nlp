{"data_csv": "/Users/petermartigny/work/experiments/nlp/data/nmt/simplest_eng_fra.csv",
"vectorizer_file": "vectorizerNMT.json",
"model_state_file": "modelNMT.pth",
"save_dir": "/Users/petermartigny/work/experiments/nlp/models/nmt/nmt_luong_no_sampling",
"logs": "/Users/petermartigny/work/experiments/nlp/models/nmt/nmt_luong_no_sampling/logs/log1",
"glove_filepath": "/Users/petermartigny/work/experiments/nlp/data/glove/glove.6B.100d.txt",
"use_glove": false,
"embedding_size": 10,
"char_embedding_size": 50,
"rnn_hidden_size": 10,
"hidden_dim": 10,
"num_channels": 10,
"seed": 1337,
"lr": 0.001,
"dropout_p": 0.1,
"batch_size": 32,
"num_epochs": 1,
"early_stopping_criteria":5,
"cuda": true,
"catch_keyboard_interrupt": true,
"reload_from_files": false,
"expand_filepaths_to_save_dir": true,
"dataset_cls": "NMTDataset",
"model": {"modelName": "NMTModel", "modelParams": ["source_vocab_size", "source_embedding_size", "target_vocab_size", "target_embedding_size", "encoding_size", "target_bos_index"],
"modelInputs": ["x_source", "x_source_lengths", "target_sequence"]},
"loss": {"lossName": "sequenceLoss", "lossParams": []},
"Optimizer": {"optimizerName": "Adam", "optimizerParams": ["params", "lr"]},
"scheduler": {"schedulerName": "ReduceLROnPlateau", "schedulerParams": ["optimizer", "mode", "factor", "patience"]},
"gradient_clipping": 0.25,
"conditioned": true,
"source_embedding_size": 64,
"target_embedding_size": 64,
"encoding_size": 64,
"is_pred_continuous": false,
"is_output_continuous": false,
"mode": "min",
"factor": 0.5,
"patience": 1,
"batch_generator": "nmt",
"metric": "accuracySequence"}
