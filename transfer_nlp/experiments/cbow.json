{"data_csv": "/Users/petermartigny/work/experiments/nlp/data/books/frankenstein_with_splits.csv",
"vectorizer_file": "vectorizerCBOW.json",
"model_state_file": "modelCBOW.pth",
"save_dir": "/Users/petermartigny/work/experiments/nlp/models/cbow",
"logs": "/Users/petermartigny/work/experiments/nlp/models/cbow/logs/log1",
"glove_filepath": "/Users/petermartigny/work/experiments/nlp/data/glove/glove.6B.100d.txt",
"use_glove": false,
"embedding_size": 100,
"hidden_dim": 10,
"num_channels": 10,
"seed": 1337,
"lr": 0.001,
"dropout_p": 0.1,
"batch_size": 128,
"num_epochs": 20,
"early_stopping_criteria":5,
"cuda": true,
"catch_keyboard_interrupt": true,
"reload_from_files": false,
"expand_filepaths_to_save_dir": true,
"dataset_cls": "CBOWDataset",
"model": {"modelName": "CBOWClassifier", "modelParams": ["vocabulary_size", "embedding_size"]},
"loss": {"lossName": "CrossEntropyLoss", "lossParams": []},
"Optimizer": {"optimizerName": "Adam", "optimizerParams": ["params", "lr"]},
"scheduler": {"schedulerName": "ReduceLROnPlateau", "schedulerParams": ["optimizer", "mode", "factor", "patience"]},
"gradient_clipping": 0.25,
"is_pred_continuous": true,
"is_output_continuous": false,
"mode": "min",
"factor": 0.5,
"patience": 1}